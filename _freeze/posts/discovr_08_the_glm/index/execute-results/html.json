{
  "hash": "1165969e091e0d93343e211a4ccc1d04",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"discover_08 - General Linear Model\"\nauthor: \"Colin Madland\"\ndate: \"2024-02-26\"\ncategories: [regression, R, discovr]\neditor: visual\nimage: \"image.jpg\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse, ggplot2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nalbum_tib <- here::here(\"data/album_sales.csv\") |> readr::read_csv()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 200 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): album_id\ndbl (4): adverts, sales, airplay, image\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nsoc_anx_tib <- here::here(\"data/social_anxiety.csv\") |> readr::read_csv()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 134 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): spai, iii, obq, tosca\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nmetal_tib <- here::here(\"data/metal_health.csv\")  |> readr::read_csv()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 2506 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): hm, suicide\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n# Fitting the Linear Model\n\n-   scatterplots to get an idea of whether assumption of linearity is met, look for outliers or other unusual cases\n-   run an initial regression and save the diagnostics\n-   if we want to generalize or test for significance or confidence intervals...\n    -   examine residuals for homoscedasticity, independence, normality, and linearity\n        -   lack of linearity --\\> fit a non-linear model\n        -   assumptions met and no bias --\\> Model can be generalized\n        -   lack of independent errors --\\> multi-level model\n        -   all other situations --\\> fit a robust version of the model using bootstrapping (small samples) or robust standard errors\n\n![General process of fitting a linear model from `discovr_08`](dsr2_fig_08_12_glm_process.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalbum_tib\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 200 × 5\n   album_id adverts sales airplay image\n   <chr>      <dbl> <dbl>   <dbl> <dbl>\n 1 aox1foms    10.3   330      43    10\n 2 u453js2i   986.    120      28     7\n 3 pie89xnr  1446.    360      35     7\n 4 u2k5a0df  1188.    270      33     7\n 5 t4699ux3   575.    220      44     5\n 6 s4h49cu2   569.    170      19     5\n 7 1235a8sf   472.     70      20     1\n 8 p2v24p5k   537.    210      22     9\n 9 4fbjg024   514.    200      21     7\n10 e9w6usdb   174.    300      40     7\n# ℹ 190 more rows\n```\n\n\n:::\n:::\n\n\n-   Use `GGally::ggscatmat` package to visualize the data\n-   produces\n    -   a matrix of scatterplots below the diagonal\n    -   distributions along the diagonal\n    -   the correlation coefficient above the diagonal\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGGally::ggscatmat(album_tib, columns = c(\"adverts\", \"airplay\", \"image\", \"sales\"))  +\ntheme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## Interpretation\n\n-   3 predictors have reasonably linear relationships with album sales and no obvious outliers (except bottom left of 'band image' scatterplots)\n-   across the diagonal (distributions)\n    -   advertising is very skewed\n    -   airplay and sales look heavy-tailed\n-   correlations in the plot give us an idea of the relationships between predictors and outcome\n-   if we ignore album sales, the highest correlation is between image ratings and amount of airplay, which is significant and the 0.01 level ($r=0.18$)\n-   focussing on the outcome variable, adverts and airplay correlate best with the outcome ($r=0.58$ and $r=0.6$)\n\n## One predictor\n\n### Fitting the model\n\n-   predicting sales from advertising alone\n\n$$Y_i=b_0+{b_1}{X_i}+\\epsilon_i$$\n\n$$\\text{Sales}_i=b_0+{b_1}{\\text{Advertising}_i}+\\epsilon_i$$\n\n-   it is clear from the bottom left scatterplot and the correlation ($r=0.58$) that a positive relation exists. More advertising money spent leads to greater album sales.\n-   some albums sell well regardless of advertising (top-left of scatterplot)\n-   no albums sell badly when adverts are high (bottom-right of scatterplot)\n-   to fit a linear model, we use `lm()` function `my_model <- lm(outcome ~ predictor(s), data = tibble, na.action = an action)`\n    -   `my_model` is the name of the model\n    -   `outcome` is the name of the outcome variable (sales)\n    -   `predictor` is the name of the predictor variable (adverts) or, a list of variables separated by `+` symbols\n    -   `tibble` is the name of the tibble containing the data (album_tib)\n-   this function maps directly to the equation for the model\n    -   `adverts ~ sales` maps to $\\text{Sales}_i=b_0+{b_1}{\\text{Advertising}_i}+\\epsilon_i$ except we ignore the error term and parameter estimates and we replace the `=` with `~` (which means 'predicted from')\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalbum_lm <- lm(sales ~ adverts, data = album_tib, na.action = na.exclude)\nsummary(album_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sales ~ adverts, data = album_tib, na.action = na.exclude)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-152.949  -43.796   -0.393   37.040  211.866 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.341e+02  7.537e+00  17.799   <2e-16 ***\nadverts     9.612e-02  9.632e-03   9.979   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 65.99 on 198 degrees of freedom\nMultiple R-squared:  0.3346,\tAdjusted R-squared:  0.3313 \nF-statistic: 99.59 on 1 and 198 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\nbroom::glance(album_lm)  |> \n  knitr::kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n| r.squared| adj.r.squared|  sigma| statistic| p.value| df|    logLik|      AIC|     BIC| deviance| df.residual| nobs|\n|---------:|-------------:|------:|---------:|-------:|--:|---------:|--------:|-------:|--------:|-----------:|----:|\n|     0.335|         0.331| 65.991|    99.587|       0|  1| -1120.688| 2247.375| 2257.27| 862264.2|         198|  200|\n\n\n:::\n:::\n\n\n\n- note $df=1$ and $df.residual=198$ therefore we can say that adding the predictor of advertising significantly improved the fit of the model to the data compared to having no predictors in the model\n- $F(1,198)=99.59, p<.001$\n\n### Model Parameters\n\nTo see model parameters, use `broom::tidy()`\n\n`broom::tidy(model_name, conf.int = FALSE, conf.level = 0.95)`\n\n- put the model name into the function, then two optional arguments\n  - confidence intervals `conf.int=TRUE` (confidence intervals are not included by default)\n  - default is 95%, but you can change it with `conf.level=.99` for 99% confidence interval\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbroom::tidy(album_lm, conf.int = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 (Intercept) 134.       7.54        17.8  5.97e-43 119.       149.   \n2 adverts       0.0961   0.00963      9.98 2.94e-19   0.0771     0.115\n```\n\n\n:::\n:::\n\n\n- output provides estimates of the model parameters ($\\hat{b}$-values)\n- $Y$ intercept ($b_0$) is 134.14 (when $X$ is 0, sales will be 134140)\n- $X$ ($b_1$) is 0.096. \n  - represents the change in outcome associated with a unit change in predictor.\n  - when the predictor increases by 1, the outcome increases by .096, but since the units of measurement was thousands of pounds and thousands of sales, an increase in $1000 will lead to 96 more albums sold\n  - not very good return\n  - BUT, we know that advertising only accounts for 1/3 of the variance\n- If a predictor is having a significant impact on our ability to predict the outcome, then $\\hat{b}$ should be different from 0 and large relative to its standard error\n- the $t$-test (labelled statistic) and the associated $p$-value tell us whether the $\\hat{b}$ is significantly different from 0\n- the column p.value contains the exact probability that a value of $t$ at least as big as the one in the table would occur if the value of $b$ in the population were 0\n- if this propbability is less than 0.05, then we interpret that as the predictor being a significant predictor of hte outcome.\n- for both $t$s, the probabilities are in scientific notation \n  - `2.91e-19` means $2.91*10^{-19}$, or `move the decimal 19 places to the left` or `0.000000000000000000291`\n  -  `2.91e+19` means $2.91*10^{19}$, or `move the decimal 19 places to the right` or `29100000000000000000`  \n- both values are 0 at 3 decimal places\n  \n### Exploring the standard error of $\\hat{b}$\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/3L9ZMdzJyyI?si=ET90VDYq3RVKnKDq\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n\n### Confidence intervals for $\\hat{b}$\n\nImagine we collect 100 samples of data measuring the same variables as the current model, then estimate the same model, including confidence intervals for unstandardized values.The boundaries are constructed such that  95% of our 100 samples contain the population value of $b$. 95 of 100 sample will yield confidence intervals for $b$ that contain the population value, but we don't know if our sample is one of the 95.\n\nWe might just assume that it does, but if the confidence interval contains 0, then there is a possibility that there is no relationship, or the relationship might be negative. The trouble is that we would be wrong 5% of the time.\n\nIf the interval does not contain 0, we might conclude there is a genuine positive relationship.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}